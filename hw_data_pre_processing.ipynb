{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dataset Overview and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Load the Ames Housing Dataset\n",
    "- Use the `fetch_openml` function from `sklearn.datasets` to load the Ames Housing dataset. Make sure to convert it to a pandas DataFrame for easy manipulation.\n",
    "\n",
    "> ref: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html\n",
    "  \n",
    "  **Note:** The target variable is `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example code for loading the Ames Housing dataset from OpenML\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_openml(data_id=42165, as_frame=True) \n",
    "df_housing = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df_housing['SalePrice'] = data.target  \n",
    "df_housing.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Summary Statistics\n",
    "- Calculate key summary statistics (mean, median, variance, standard deviation) for all features in the dataset.\n",
    "- Discuss the importance of each statistical measure in understanding the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        mean           std       50%      variance\n",
      "Id                730.500000    421.610009     730.5  1.777550e+05\n",
      "MSSubClass         56.897260     42.300571      50.0  1.789338e+03\n",
      "LotFrontage        70.049958     24.284752      69.0  5.897492e+02\n",
      "LotArea         10516.828082   9981.264932    9478.5  9.962565e+07\n",
      "OverallQual         6.099315      1.382997       6.0  1.912679e+00\n",
      "OverallCond         5.575342      1.112799       5.0  1.238322e+00\n",
      "YearBuilt        1971.267808     30.202904    1973.0  9.122154e+02\n",
      "YearRemodAdd     1984.865753     20.645407    1994.0  4.262328e+02\n",
      "MasVnrArea        103.685262    181.066207       0.0  3.278497e+04\n",
      "BsmtFinSF1        443.639726    456.098091     383.5  2.080255e+05\n",
      "BsmtFinSF2         46.549315    161.319273       0.0  2.602391e+04\n",
      "BsmtUnfSF         567.240411    441.866955     477.5  1.952464e+05\n",
      "TotalBsmtSF      1057.429452    438.705324     991.5  1.924624e+05\n",
      "1stFlrSF         1162.626712    386.587738    1087.0  1.494501e+05\n",
      "2ndFlrSF          346.992466    436.528436       0.0  1.905571e+05\n",
      "LowQualFinSF        5.844521     48.623081       0.0  2.364204e+03\n",
      "GrLivArea        1515.463699    525.480383    1464.0  2.761296e+05\n",
      "BsmtFullBath        0.425342      0.518911       0.0  2.692682e-01\n",
      "BsmtHalfBath        0.057534      0.238753       0.0  5.700283e-02\n",
      "FullBath            1.565068      0.550916       2.0  3.035082e-01\n",
      "HalfBath            0.382877      0.502885       0.0  2.528937e-01\n",
      "BedroomAbvGr        2.866438      0.815778       3.0  6.654938e-01\n",
      "KitchenAbvGr        1.046575      0.220338       1.0  4.854892e-02\n",
      "TotRmsAbvGrd        6.517808      1.625393       6.0  2.641903e+00\n",
      "Fireplaces          0.613014      0.644666       1.0  4.155947e-01\n",
      "GarageYrBlt      1978.506164     24.689725    1980.0  6.095825e+02\n",
      "GarageCars          1.767123      0.747315       2.0  5.584797e-01\n",
      "GarageArea        472.980137    213.804841     480.0  4.571251e+04\n",
      "WoodDeckSF         94.244521    125.338794       0.0  1.570981e+04\n",
      "OpenPorchSF        46.660274     66.256028      25.0  4.389861e+03\n",
      "EnclosedPorch      21.954110     61.119149       0.0  3.735550e+03\n",
      "3SsnPorch           3.409589     29.317331       0.0  8.595059e+02\n",
      "ScreenPorch        15.060959     55.757415       0.0  3.108889e+03\n",
      "PoolArea            2.758904     40.177307       0.0  1.614216e+03\n",
      "MiscVal            43.489041    496.123024       0.0  2.461381e+05\n",
      "MoSold              6.321918      2.703626       6.0  7.309595e+00\n",
      "YrSold           2007.815753      1.328095    2008.0  1.763837e+00\n",
      "SalePrice      180921.195890  79442.502883  163000.0  6.311111e+09\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df_housing.describe().loc[['mean', 'std', '50%']].T  # 50% is the median\n",
    "summary_stats['variance'] = df_housing.select_dtypes(include='number').var()\n",
    "summary_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "print(summary_stats)\n",
    "\n",
    "\n",
    "# df_housing.median()    \n",
    "# df_housing.var()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Data Visualization\n",
    "- Create visualizations to explore relationships between features. This should include:\n",
    "  - Histograms for each feature to observe the distribution.\n",
    "  - Pair plots to examine relationships between features.\n",
    "  - A correlation matrix to analyze correlations between numerical variables and their effect on the target (`SalePrice`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Handle Categorical Variables\n",
    "- Visualize and analyze categorical variables such as `Neighborhood`, `ExterQual`, and `HouseStyle`.\n",
    "- Understand the distribution of these categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Document Key Insights\n",
    "- Document key insights from the EDA, such as:\n",
    "  - Highly correlated features.\n",
    "  - Potential outliers.\n",
    "  - Visible patterns or trends.\n",
    "- Identify any preliminary issues that may affect model performance (e.g., outliers, missing values, categorical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Training a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Convert Categorical Features to Numerical\n",
    "- Use encoding techniques such as `One-Hot Encoding` or `Label Encoding` to convert categorical features into numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Split the Dataset\n",
    "- Split the dataset into training and testing sets using an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Train a Gradient Descent-Based Regression Model\n",
    "- Train a regression model (such as a Linear Regression model using Gradient Descent) on the raw dataset.\n",
    "- Record the baseline performance using appropriate regression evaluation metrics (e.g., Mean Squared Error (MSE), Root Mean Squared Error (RMSE))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4: Document Model Performance\n",
    "- Document the performance of the baseline model. \n",
    "- Explain the significance of the evaluation metrics you have chosen.\n",
    "- Explain which encoding technique best suited the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Data Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Handling Missing Data\n",
    "- For this step use the best version of preprocessed dataset from previous steps.\n",
    "- The dataset contains missing values in various columns. Apply the following imputation techniques:\n",
    "  - Removing rows with missing values.\n",
    "  - Imputation using `mean`, `median`, and `mode`.\n",
    "- Retrain the model after handling missing data and compare the performance with the baseline model.\n",
    "\n",
    "#### Findings:\n",
    "- Compare the model performance before and after handling missing data.\n",
    "- Which imputation technique led to the best performance? Why?\n",
    "- Document the effects of each method on model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Data Normalization and Standardization\n",
    "- Apply the following scaling techniques to numerical features:\n",
    "  - `Min-Max Scaling`.\n",
    "  - `Z-score Standardization` (mean = 0, variance = 1).\n",
    "- Retrain the model on normalized and standardized datasets, and compare the performance against the baseline.\n",
    "\n",
    "#### Findings:\n",
    "- Compare the model performance before and after applying normalization and standardization.\n",
    "- How do normalization and standardization impact model performance?\n",
    "- Discuss which method improved model performance the most and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3: Outlier Detection and Removal\n",
    "- Detect and potentially remove outliers in both numerical and categorical data using:\n",
    "  - `Z-score` method for numerical features.\n",
    "  - Frequency analysis for categorical features (e.g., rare categories in `Neighborhood`). [*OPTIONAL*]\n",
    "- Retrain the model after removing outliers and evaluate its performance.\n",
    "\n",
    "#### Findings:\n",
    "- How did the removal of outliers affect model performance?\n",
    "- Did outlier removal improve or degrade the model’s accuracy? Provide insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.4: Feature Engineering\n",
    "- Apply feature engineering techniques such as:\n",
    "  - Creating polynomial features (e.g., `quadratic` or `cubic features` or `logarithmic transformations`).\n",
    "  - Interaction features (e.g., combining features like `GrLivArea` and `OverallQual`).\n",
    "- Retrain the model using the engineered features and compare the performance.\n",
    "\n",
    "#### Findings:\n",
    "- Did feature engineering improve the model's performance?\n",
    "- Which feature transformations had the most significant effect on model accuracy?\n",
    "- Justify why certain features may have contributed to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Regularization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Apply Ridge Regression ($L2$)\n",
    "- Train a Ridge regression model on the preprocessed dataset (after applying necessary scaling, imputation, and encoding).\n",
    "- Use cross-validation to find the optimal value of the regularization parameter (`alpha`).\n",
    "\n",
    "#### Findings:\n",
    "- Compare the performance of Ridge regression with the baseline linear regression model.\n",
    "- How did Ridge regularization affect the model’s performance in terms of reducing overfitting and improving generalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: Apply Lasso Regression ($L1$)\n",
    "- Train a Lasso regression model on the preprocessed dataset.\n",
    "- Use cross-validation to find the optimal value of the regularization parameter ($\\alpha$).\n",
    "  \n",
    "#### Findings:\n",
    "- Compare the performance of Lasso regression with both the baseline model and the Ridge regression model.\n",
    "- Did Lasso shrink any coefficients to zero? If so, which features were eliminated, and why might they be considered less important?\n",
    "- Analyze how Lasso improved the model's generalization and whether feature selection helped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.3: Comparison of Ridge and Lasso\n",
    "- Compare the performance of Ridge and Lasso regression models.\n",
    "- Discuss the trade-offs between the two approaches in terms of:\n",
    "  - Feature selection (sparsity in Lasso vs. retaining all features in Ridge).\n",
    "  - Impact on overfitting and model interpretability.\n",
    "  - Which model performed better on the Ames Housing dataset, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Summary and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1: Summary of Findings\n",
    "- Summarize your findings from each preprocessing technique (handling missing data, normalization, standardization, outlier removal, feature engineering).\n",
    "- Clearly compare the performance of the regression model after each preprocessing step to the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2: Conclusion\n",
    "- Reflect on the importance of data preprocessing in machine learning.\n",
    "- Which preprocessing techniques had the most significant impact on model performance, and why?\n",
    "- Discuss how these insights might be applied to real-world machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
